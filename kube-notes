export KOPS_STATE_STORE=s3://kube.jaymell.net
kops create cluster \
  --zones=us-east-1c \
  --channel "stable" \
  useast1.kube.jaymell.net

kops edit cluster useast1.kube.jaymell.net
kops update cluster useast1.kube.jaymell.net --yes
kops rolling-update cluster

# change node properties:
kops edit ig nodes

# change master properties:
kops edit ig master-us-east-1c

kops validate cluster

kubectl run kubernetes-bootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1 --port=8080

# docker logins
kubectl create secret docker-registry regcred --docker-server=<your-registry-server> --docker-username=<your-name> --docker-password=<your-pword> --docker-email=<your-email>

kubectl get deployments --sort-by=.metadata.name

# change default node/master volume size:
kops edit ig nodes
# Add this under spec:
rootVolumeSize: 20
kops edit ig master-us-east-1c
# Add this under spec:
rootVolumeSize: 20

# change default etcd volume sizes:
kops edit cluster useast1.kube.jaymell.net
# Add this to each etcdClusters.etcdMembers array item:
volumeSize: 5
.e.g, :
etcdClusters:
- etcdMembers:
  - instanceGroup: master-us-east-1c
    name: c
    volumeSize: 5
  name: main
- etcdMembers:
  - instanceGroup: master-us-east-1c
    name: c
    volumeSize: 5
  name: events



# mongo
# create service
kubectl create -f service.yml
kubectl create -f deploy.yml --record
# temporary to enable a place to restore to remotely (dumb):
kubectl expose deployment mongo-deployment --type=LoadBalancer --name=mongo
mongorestore --db logger ./logger/ --host acd2690568bdd11e88ee20abe3ad70ae-346744967.us-east-1.elb.amazonaws.com

# ipmapper
kubectl create -f service.yml
kubectl create -f deploy.yml --record
kubectl expose deployment ipmapper-deployment --type=LoadBalancer --name=ipmapper


# ingress-controller
kubectl create -f service.yml
kubectl create -f deploy.yml


# helm
tar xvf helm-v2.10.0-linux-amd64.tar.gz
cd helm-2.10.0/
mv linux-amd64/helm ~/bin/
helm init


helm fetch stable/nginx-ingress

# tiller service account
kubectl create serviceaccount --namespace kube-system tiller
kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller
kubectl patch deploy --namespace kube-system tiller-deploy -p '{"spec":{"template":{"spec":{"serviceAccount":"tiller"}}}}'


# install helm services

# postgres standalone w/ manifest overrides:
helm install -n postgresql -f ../../values.yaml .
