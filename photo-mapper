
db record format:
. md5sum -- for both:
.. filename
.. uniqueness
. label name 
. coordinates
. date/time
. width/height
. user name

import steps:
1) prompt for label name for
imported files (ie, '2015 vacation')

2) read files
. md5sum compare against DB entries
 ( and file system ?? ) 
. if unique:
.. copy file with md5sum name
into directory... 
.... if copy successful:

3) put as much of above info as possible
into db
... if you can't read any of it, store only
	the file name (md5sum)
... if db entry NOT successful:
..... delete file


--------------
keeping map and list in sync:
. not every item in list has pin
. every pin has an item in list

when list item clicked:
. set pin center of map
.. animate?
. change zoom level ?
.. not currently
. change pin color
. change list item color

when pin clicked
. change pin color
. change list item color

--------------------
client-side workflow:
. initialize map
. get photo json from server
. for each json entry:
	add item (a tag) to list on left
	add item to photoArray (for photoSwipe -- this
	 could actually just be the json itself, if not for
	 photoSwipe requiring 'h', 'w', and 'src' tags 
	 specifically )
. add photoSwipe click handlers to items in list
. add pins to map
. add additional listeners to items in list, but these
are done by delegating through a tags' parent div, not
on individual items:
	center on map Pin
	change color of viewed Pins


-----------------
import country geojson
### first have to strip off "featureCollection" tag, then wrap entire file in array brackets:
mongoimport --drop --db photo_mapper --collection countries --type json --file countries.geojson --jsonArray
# find in Mongo client:
var italy = db.countries.findOne({'properties.admin': 'Italy'})


# scratch:
var monk = require('monk');

var db = monk('localhost:27017/photo_mapper');
var photoCol = db.get('photo_mapper');
var countryCol = db.get('countries');
var photos = [];
var countries = [];

// temporary var to hold photo data converted
// to geojson, ultimately I need to make the photo 
// records themselves hold this data:
photoCol.find({}, function(e,docs){
	docs.forEach(function(i) { 
		console.log(i);
		if (i.longitude && i.latitude) {
			photos.push(
				geometry: {
					"type": "Point",
					"coordinates": [
						i.longitude,  
						i.latitude 
					]}
			); 
		}
	});
});

// same as above but put it into separate
// collection instead of variable:
var pointCol = db.get('points')
var photos = [];
photoCol.find({}, function(e,docs){
	photos = docs;
});
photos.forEach(function(i) {
	if (i.longitude && i.latitude) {
		pointCol.insert(
		{
			geometry: { 
				"type": "Point",
				"coordinates": [
					i.longitude,
					i.latitude
				]
			}
		},
		function(err, docs) {
			if (err) throw err;
		});
	}
});


// find italy and assign to var:
var italy; 
countryCol.findOne({'properties.admin': 'Italy'}).on('success', function(doc) { italy = doc; });


// now see if it can find photos within Italy:
pointCol.find(
	{
		geometry: { 
			$geoWithin: { 
				$geometry: italy.geometry
			}
		}
	},
	function(err, docs) {
		docs.forEach(function(curr) {
			console.log(curr);
		});
	}
);

var point = {
  "type": "Point",
  "coordinates": [
    longitude,  
    latitude 
  ]
};

// iterate through countries, find photos that fall within
// them:
// Antarctica, Russia, and Fiji throw errors:
var countries;
countryCol.find({}).on('success', function(doc) { countries = doc; });
countries.forEach(function(country) {
	photoCol.find(
		{
			geojson: {
				$geoWithin: {
					$geometry: country.geometry
				}
			}
		},
		function(err, docs) {
			if (err) console.log(country.properties.admin,' error: ',err);
			if (docs) {
				docs.forEach(function(curr) {
					console.log(curr);
				});
			}
		}
	);
});
------------------------
steps for adding country data:
. test 

quality=30 -- total size 218M
full quality -- total size 441M


--------------------------
plotting /clustering notes:

from pymongo import MongoClient
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from scipy.cluster.vq import kmeans, kmeans2, whiten
from sklearn.cluster import DBSCAN

MONGODB_HOST = '192.168.1.69'
MONGODB_PORT = 27017
DB_NAME = 'photo_mapper'
COLLECTION_NAME='photo_mapper'
connection = MongoClient(MONGODB_HOST, MONGODB_PORT)
collection = connection[DB_NAME][COLLECTION_NAME]

raw_results = [ i for i in collection.find() ]
results = 	[ i['geojson']['coordinates'] 
				for i in collection.find() 
				# compound if sucks, maybe better way to get truth of all elements in array:
				if i['geojson']['coordinates'][0] 
				and i['geojson']['coordinates'][1] 
			]

# save scatter plot of coordinates plotted on graph:
df = pd.DataFrame(results)
df.columns = ['longitude','latitude']
df.plot.scatter('longitude', 'latitude')
#plt.savefig('/tmp/out.png')

#http://geoffboeing.com/2014/08/clustering-to-reduce-spatial-data-set-size/
coordinates = df.as_matrix(columns=['longitude', 'latitude'])
N = len(coordinates)
k = 20
i = 50
w = whiten(coordinates)
cluster_centroids, closest_centroids = kmeans2(w, k, iter=i, minit='points')

plt.figure(figsize=(10, 6), dpi=100)
plt.scatter(cluster_centroids[:,0], cluster_centroids[:,1], c='r', alpha=.7, s=150)
plt.scatter(w[:,0], w[:,1], c='k', alpha=.3, s=10)
plt.show()

rs = pd.DataFrame(df)
rs['closest_centroid'] = closest_centroids
rs.drop_duplicates(subset=['closest_centroid'], take_last=False, inplace=True)
rs.head()


plt.figure(figsize=(10, 6), dpi=100)
rs_scatter = plt.scatter(rs['longitude'], rs['latitude'], c='r', alpha=.7, s=150)
df_scatter = plt.scatter(df['longitude'], df['latitude'], c='k', alpha=.3, s=5)
plt.title('Full data set vs k-means reduced set')
plt.legend((df_scatter, rs_scatter), ('Full set', 'Reduced set'), loc='upper left')
plt.xlabel('Longitude')
plt.ylabel('Latitude')
plt.show()


#df = pd.DataFrame(results)
#df.columns = ['longitude','latitude']
#coordinates = df.as_matrix(columns=['longitude', 'latitude'])
def dbscan_stuff(coordinates):
	""" take coordinate dataframe, print number of 
		clusters -- http://geoffboeing.com/2014/08/
					clustering-to-reduce-spatial-data-set-size/ """
	db = DBSCAN(eps=.01, min_samples=1).fit(coordinates)
	labels = db.labels_
	num_clusters = len(set(labels)) - (1 if -1 in labels else 0)
	clusters = pd.Series([coordinates[labels == i] for i in xrange(num_clusters)])
	print('Number of clusters: %d' % num_clusters)

dbscan_stuff(coordinates)


###############################################################
file uploads
. files get uploaded to endpoint /api/users/<user>/albums/<album>/photos 
. server:
	-- save files to UPLOAD_DIR/TEMPDIR (python module tempdir for TEMPDIR)
	-- process files -- use existing import_data code
		-- put json in db
 		-- send to s3
	-- delete tempdir

############################################
deployment

__ build app / image
. build Dockerfile
	.. tag image the way aws wants you to 
. send image to registry
	.. aws cli for docker login and push to registry
aws ecr get-login --region us-east-1
docker build -t photo_mapper .
docker tag adf:latest 799617403160.dkr.ecr.us-east-1.amazonaws.com/adf:latest
docker push 799617403160.dkr.ecr.us-east-1.amazonaws.com/adf:latest



__ to docker / aws ecs
. create security groups
	.. outbound ?
	.. inbound based on apps
. create docker instances based on desired count
	.. add to inventory group
. run ansible 'docker' role to install docker
BETTER: just use aws ecs instances
. install pip and docker-py python module on docker
	hosts if using ansible to actually help run docker containers
. docker run 
	### there are ansible modules for the following stuff ###
. set up ecs registry in region us-east-1 -- and this region ONLY
	.. aws cli
. give machine that will build docker images registry access
	.. either via user account with proper role 
	.. or just give whole instance role to push to registry
. create iam role for ecs service that runs on each instance
	.. type: ec2 service 
	.. attach policy: AmazonEC2ContainerServiceforEC2Role
. give read/write polciy to s3 bucket where app static content stored
. read-only s3 access so instances can get /etc/ecs/ecs.config
	at launch time (for ecs cluster agent)

. create ecs task definition -- basically, your 'docker run'
	syntax

. create instances or auto-scaling group (your docker hosts)
	.. associate above-created role with them

. create ecs cluster

. create service to associate with cluser
	.. specifies number of containers that will be run and
		whether or not they're behind an ELB
	.. give service permission via ecsServiceRole to do stuff

. create load balancer that service will assign itself to

.... need to fully document process of joining 'container instance'
	to cluster. they will auto-join clusters named 'default', but may
	need some run-time aws-cli commands stuffed into user data to
	get more complicated than that

# manually uploading a file via curl:
curl -i -X POST -H "Content-Type: multipart/form-data" -F "data=@20150908_152122.jpg" http://i7w/api/users/james/albums/testy/photos

#######
aborted db formats:
########
### only semi-cram entire thing into one doc:
user_name: james
albums: 
  - name: kayaking
    photos:
    - date: '2015-09-23 01:34:37'
      geojson:
        coordinates: 
        - 76.73065830555555
        - 9.623579805555556
        type: point
      md5sum: 'ba59718b48662068e9be6ba729f19e81'
      sizes: 
        full:
          height: 2560
          name: 'ba59718b48662068e9be6ba729f19e81.jpg'
          width: 1920

---
#### cram entire application into one __document__? 
	maybe not the best idea.....
Users:
  james:
    albums: 
      vacation:
        photos:
        - date: '2015-09-23 01:34:37'
          geojson:
            coordinates: 
            - 76.73065830555555
            - 9.623579805555556
            type: point
          md5sum: 'ba59718b48662068e9be6ba729f19e81'
          sizes: 
            full:
              height: 2560
              name: 'ba59718b48662068e9be6ba729f19e81.jpg'
              width: 1920
api classes:
#http://blog.miguelgrinberg.com/post/designing-a-restful-api-using-flask-restful
class UserListAPI
	get: get all users? Probably shouldn't allow this
	post: add user -- how is authentication for this handled? does the client actually do this itself?
	route: /api/users/
class UserAPI
	put: update user info, not albums or photos though
	get: get user-related info
	delete: How is this handled? Who has permission to fully delete a user account?
	route: /api/users/<user> -- is <user> name or id?
class AlbumListAPI
	post: add album
	get: get all albums
	route: /api/users/<user>/albums
class AlbumAPI
	put: update album info, except for photos		
	route: /api/users/<user/albums/<album>
class PhotoListAPI
	post: add photo
	get: all photos
	route: /api/users/<user>/albums/<album>/photos
class PhotoAPI
	put: update photo
	get: invidivual photo
	delete: delete photo
	route: /api/users/<user>/albums/<album>/photos/<photo>

quick steps to test mongo within python
##############
from pymongo import MongoClient
MONGODB_HOST = 'localhost'
MONGODB_PORT = 27017
COLLECTION_NAME = 'photo_mapper'
DB_NAME = 'photo_mapper'
db = MongoClient(MONGODB_HOST, MONGODB_PORT)
col = db[DB_NAME][COLLECTION_NAME]
#############

create database photo_mapper;
create user 'pm'@'localhost' identified by 'ohsh7Shi';
create user 'pm'@'%' identified by 'ohsh7Shi';
grant all privileges on photo_mapper.* to 'pm'@'%';

# quick initialize of db:
import photo_mapper as pm
pm.db.create_all()

# query:
import photo_mapper as pm
import photo_mapper.models as models
models.User.query()

# insert:
user = models.User('bill')
pm.db.session.add(user)
pm.db.session.commit()

# post user:
curl -H "Content-Type: application/json" -X POST -d '{"user_name": "james", "email": "email@gmail.com", "password1": "StrongPassword", "password2": "StrongPassword"}' http://localhost:5000/api/users

curl -H "Content-Type: application/json" -X POST -d \
	'{ \
		"user_name": "franklin", \
		"email": "email@gmail.com", \
		"password1": "StrongPassword", \
		"password2": "StrongPassword" \
	}' \
	http://localhost:5000/api/users

# post album:
curl -H "Content-Type: application/json" -X POST -d '{"album_name": "vacation"}' http://localhost:5000/api/users/1/albums
# post photos in a loop:
for i in `ls -C /home/james/Pictures/2015-vacation/james/*jpg`;   do  curl -i -X POST -H "Content-Type: multipart/form-data" -F "data=@""${i}" http://localhost:5000/api/users/james/photos; done
# put photo update:
curl -X PUT -d album_id=1 album_id=2 http://localhost:5000/api/users/james/photos/597

# for testing jpeg object:
import photo_mapper.photo_importer as pi
a = pi.Jpeg(open("/home/james/Pictures/2015-vacation/james/20150911_045437.jpg"))

# create admin role:
insert into role (role_name) VALUES ('Administrator');

### current -- routes for photos and albums container user_id:
@auth.login_required
/api/users/<user_id>/photos
1) auth:
	-- if valid token passed, query database for user id; return user object
	-- if token auth fails, query database for user name, check password against hash
2) use flask.g.user in route method:
	-- if user_id in route matches flask.g.user.user_id, allow access
	-- else if flask.g.user has ADMIN role
Downsides:
	-- it's sort of pointless to require passing user ID in route when you already know it based on token
	-- it requires client to have to know / keep user ID, even though it's not really needed

### if photos or albums don't require user id in route:
@auth.login_required
/api/photos
1) auth:
	-- if valid token passed, query database for user id; return user object
	-- if token auth fails, query database for user name, check password against hash
2) use flask.g.user in route method:
	-- if photo is owned by user_id, allow access
	-- else if user has ADMIN role
Downsides:
	-- requires re-doing stuff
	-- the logic might be complicated to reconcile what resources user has by virtue of owning the resources
		vs having permission based on a role

### the on_identity_loaded() function:
. if user is user_id for album or photo, it has permission
. if user has admin role, it has permission to access photo / album
. how to delegate permissions, oauth style, for one user to another -- ie, the user associated with
	external application has access to user 643's albums and photos because user 643 granted it, outh style
. what about read-all stuff
. how are permissions to photos within album handled when permission granted to album
. how is permission to STATIC content handled -- is this possible without signed links?	


############ API Documentationing

# permission types:
. full access to own files
. administrator -- full read/write
### LATER:
. read-only to someone else's photos
. photos marked as read-all
... no plans to add write access to other users... just admin role

/api/users
# administrator access required
.get
# not sure how to handle permissions here -- anonymous but token required?
.post
# user or admin:
.delete -- eg, delete own account


/api/users/<user_id>/
# user or administrator access required
.get
.put

/api/users/<user_id>/albums
# user or administrator access required
.get
.post
.delete

/api/users/<user_id>/albums/<album_id>
# user or admin
.get
.put

/api/users/<user_id>/photos
# user or admin
.get
.post
.delete


/api/users/<user_id>/photos/<photo_id>
# user or admin
.get
.put

# stuff left to do to make this work:
. add user roles


## How authentication works
* flask.ext.httpauth.HTTPBasicAuth used for auth
* if @auth.login_required decorates a method, then the @auth.verify_password-decorated function is called
  -- this function (verify_pw) verifies the credentials, sends a signal to principal.identity_loaded which populates the global identity, and returns True assuming pw/token is validated


### if we want more fine-grained perms:
AlbumNeed = col.namedtuple('album', ['method', 'value'])
AlbumReadNeed = ft.partial(AlbumNeed, 'read')
 class AlbumReadPermission(pr.Permission):
   def __init__(self, album_id):
     need = AlbumReadNeed(album_id)
     role_need = pr.RoleNeed('Administrator')
     super(AlbumReadPermission, self).__init__(need, role_need)


curl -u eyJhbGciOiJIUzI1NiIsImV4cCI6MTQ4MTM0OTgxMiwiaWF0IjoxNDgxMzQ5MjEyfQ.eyJ1c2VyX2lkIjo4fQ.ALTJP8hYuZ7Bspbk0QDGxTrRgojkL82K97Qn0Dm09zU: -H "Content-Type: application/json" -X POST -d '{"album_name": "vacation"}' http://localhost:5000/api/users/8/albums


AUTH="eyJhbGciOiJIUzI1NiIsImV4cCI6MTQ4MTM1MDg3NCwiaWF0IjoxNDgxMzUwMjc0fQ.eyJ1c2VyX2lkIjo4fQ.o0_h0_0NyaT3EKK6jS1iUMUQT1eSpmG9CHEhIJ92Yd0:"


for i in `ls -C /home/james/Pictures/2015-vacation/james/*jpg`;   do  curl -i -u $AUTH -X POST -H "Content-Type: multipart/form-data" -F "data=@""${i}" http://localhost:5000/api/users/8/photos; done


/api/users/8/photos/4


AUTH="eyJhbGciOiJIUzI1NiIsImV4cCI6MTQ4MTM1Mzk3NywiaWF0IjoxNDgxMzUzMzc3fQ.eyJ1c2VyX2lkIjo4fQ.SWeWcDQ_kUC3so-POKQ12woSzWlYMAkoTXqjLW0owM8:"


curl -u $AUTH -H "Content-Type: application/json" -X PUT -d '{"album_id": 1}' http://localhost:5000/api/users/8/photos/4


curl -u $AUTH -H "Content-Type: application/json" -X POST -d '{"album_name": "vacation"}' http://localhost:5000/api/users/8/albums


curl -u $AUTH http://localhost:5000/api/users/8/albums



AUTH="eyJhbGciOiJIUzI1NiIsImV4cCI6MTQ4MTM1Mzk3NywiaWF0IjoxNDgxMzUzMzc3fQ.eyJ1c2VyX2lkIjo4fQ.SWeWcDQ_kUC3so-POKQ12woSzWlYMAkoTXqjLW0owM8:"
curl -u $AUTH  http://localhost:5000/api/users/8/albums/1

[
    {
        "album_id": 1, 
        "album_name": "vacation", 
        "photos": [
            {
                "date": "1969-12-31 19:17:19", 
                "full": {
                    "height": 1920, 
                    "name": "/static/img/0dade7e21d3866110ae677741efa485e.jpg", 
                    "size": "full", 
                    "width": 2560
                }, 
                "latitude": null, 
                "longitude": null, 
                "md5sum": "0dade7e21d3866110ae677741efa485e", 
                "photo_id": 4, 
                "scaled": {
                    "height": 900, 
                    "name": "/static/img/0dade7e21d3866110ae677741efa485e-scaled.jpg", 
                    "size": "scaled", 
                    "width": 1200
                }, 
                "sizes": [
                    {
                        "height": 900, 
                        "name": "/static/img/0dade7e21d3866110ae677741efa485e-scaled.jpg", 
                        "photoSize_id": 13, 
                        "photo_id": 4, 
                        "size": "scaled", 
                        "width": 1200
                    }, 
                    {
                        "height": 100, 
                        "name": "/static/img/0dade7e21d3866110ae677741efa485e-small.jpg", 
                        "photoSize_id": 14, 
                        "photo_id": 4, 
                        "size": "small", 
                        "width": 100
                    }, 
                    {
                        "height": 1920, 
                        "name": "/static/img/0dade7e21d3866110ae677741efa485e.jpg", 
                        "photoSize_id": 15, 
                        "photo_id": 4, 
                        "size": "full", 
                        "width": 2560
                    }, 
                    {
                        "height": 192, 
                        "name": "/static/img/0dade7e21d3866110ae677741efa485e-thumbnail.jpg", 
                        "photoSize_id": 16, 
                        "photo_id": 4, 
                        "size": "thumbnail", 
                        "width": 256
                    }
                ], 
                "small": {
                    "height": 100, 
                    "name": "/static/img/0dade7e21d3866110ae677741efa485e-small.jpg", 
                    "size": "small", 
                    "width": 100
                }, 
                "thumbnail": {
                    "height": 192, 
                    "name": "/static/img/0dade7e21d3866110ae677741efa485e-thumbnail.jpg", 
                    "size": "thumbnail", 
                    "width": 256
                }, 
                "uri": "/api/users/8/photos/4"
            }
        ], 
        "uri": "/api/users/8/albums/1"
    }
]

### install stuff with browserify
browserify -g browserify-css -t [ babelify --presets [ es2015 react ] ] photo_mapper/static/js/photo_mapper.js -o photo_mapper/static/js/bundle.js

+# if selinux nginx denial:
+setsebool httpd_can_network_connect on -P

