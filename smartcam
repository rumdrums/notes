Architecture
. 4 processes
 1) Main process
 2) . read frame thread
      -- determine / set resolution
      -- worry about framerate here?
      -- metadata:
        -- time
        -- resolution
        -- format
      -- add to QueueHandler
    . QueueHandler thread
      -- put current image on ImageProcessor and VideoProcessor queues
 3) . convert images to video
     -- read images from queue
     -- at some point, write to file
     -- add start, end, and file name to database
 4) . get frame from queue thread
    . determine if in motion
    . save in-motion start/stop times to database


motion detection loop
. current:
get frame
set self.current
if not background or background expired:
  set self.background
  write video buffer
  continue
if not in motion
  self._in_motion = self.detect_motion()
if self._in_motion:
  self.detect_motion() ### to get contours
  show image with contours drawn
  add image to video array

. instead:
if self.current:
  self.background = self.current
  self.current = self.get_frame()
in_motion = self.detect_motion()
if in_motion:
  set self.last_motion_time = self.current.time
  add self.current to video array
elif self.motion_timeout()
  write video buffer

# Maybe a clue to video format issues:
OpenCV: FFMPEG: tag 0x3234706d/'mp42' is not supported with codec id 16 and format 'avi / AVI (Audio Video Interleaved)'
OpenCV: FFMPEG: fallback to use tag 0x3234504d/'MP42'



# error in docker:
INFO:__main__:detect_objects: 0:01:01.248011
ERROR:__main__:exception: [Errno 28] No space left on device
-- it's a shared memory limitation issue

